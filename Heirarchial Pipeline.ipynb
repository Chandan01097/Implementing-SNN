{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80faf9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STAGE 1: Building and Training Beat Classifier (Model A) on MIT-BIH Data ---\n",
      "MIT-BIH dataset loaded successfully.\n",
      "Training Model A...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.3625 - val_accuracy: 0.9407 - val_loss: 0.2202\n",
      "Epoch 2/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1968 - val_accuracy: 0.9552 - val_loss: 0.1617\n",
      "Epoch 3/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1605 - val_accuracy: 0.9633 - val_loss: 0.1434\n",
      "Epoch 4/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1407 - val_accuracy: 0.9671 - val_loss: 0.1366\n",
      "Epoch 5/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9649 - loss: 0.1271 - val_accuracy: 0.9681 - val_loss: 0.1243\n",
      "Epoch 6/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.1186 - val_accuracy: 0.9677 - val_loss: 0.1227\n",
      "Epoch 7/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.1116 - val_accuracy: 0.9725 - val_loss: 0.0998\n",
      "Epoch 8/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.1068 - val_accuracy: 0.9740 - val_loss: 0.0986\n",
      "Epoch 9/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.1017 - val_accuracy: 0.9748 - val_loss: 0.0947\n",
      "Epoch 10/10\n",
      "\u001b[1m616/616\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9730 - loss: 0.0971 - val_accuracy: 0.9743 - val_loss: 0.0957\n",
      "\n",
      "Model A (Beat Classifier) Test Accuracy: 97.12%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- STAGE 3: Building and Training Diagnostic Model (B) on PTBDB Data ---\n",
      "PTBDB dataset loaded successfully.\n",
      "Applying optimized feature engineering pipeline to PTBDB data...\n",
      "\u001b[1m455/455\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n",
      "Feature engineering complete.\n",
      "\n",
      "Class Imbalance Detected. Calculated weights to compensate:\n",
      "  Weight for class 0 (Normal): 1.80\n",
      "  Weight for class 1 (Abnormal): 0.69\n",
      "\n",
      "Training Model B (with class weights)...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5095 - loss: 0.6827 - val_accuracy: 0.4266 - val_loss: 0.6654\n",
      "Epoch 2/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4198 - loss: 0.6618 - val_accuracy: 0.4026 - val_loss: 0.6817\n",
      "Epoch 3/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4308 - loss: 0.6528 - val_accuracy: 0.7142 - val_loss: 0.6283\n",
      "Epoch 4/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4611 - loss: 0.6447 - val_accuracy: 0.4601 - val_loss: 0.6431\n",
      "Epoch 5/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4549 - loss: 0.6376 - val_accuracy: 0.4910 - val_loss: 0.6244\n",
      "Epoch 6/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4643 - loss: 0.6333 - val_accuracy: 0.4712 - val_loss: 0.6362\n",
      "Epoch 7/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4689 - loss: 0.6302 - val_accuracy: 0.4592 - val_loss: 0.6514\n",
      "Epoch 8/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4835 - loss: 0.6273 - val_accuracy: 0.4781 - val_loss: 0.6299\n",
      "Epoch 9/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4771 - loss: 0.6271 - val_accuracy: 0.4695 - val_loss: 0.6441\n",
      "Epoch 10/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4857 - loss: 0.6255 - val_accuracy: 0.4841 - val_loss: 0.6364\n",
      "Epoch 11/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4876 - loss: 0.6237 - val_accuracy: 0.5202 - val_loss: 0.6174\n",
      "Epoch 12/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4858 - loss: 0.6231 - val_accuracy: 0.5356 - val_loss: 0.6113\n",
      "Epoch 13/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5016 - loss: 0.6220 - val_accuracy: 0.4652 - val_loss: 0.6550\n",
      "Epoch 14/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4963 - loss: 0.6208 - val_accuracy: 0.4773 - val_loss: 0.6446\n",
      "Epoch 15/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5028 - loss: 0.6198 - val_accuracy: 0.4815 - val_loss: 0.6384\n",
      "Epoch 16/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5019 - loss: 0.6186 - val_accuracy: 0.5210 - val_loss: 0.6200\n",
      "Epoch 17/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5108 - loss: 0.6178 - val_accuracy: 0.5107 - val_loss: 0.6284\n",
      "Epoch 18/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5167 - loss: 0.6169 - val_accuracy: 0.4833 - val_loss: 0.6411\n",
      "Epoch 19/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5177 - loss: 0.6162 - val_accuracy: 0.4824 - val_loss: 0.6447\n",
      "Epoch 20/20\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5183 - loss: 0.6159 - val_accuracy: 0.5236 - val_loss: 0.6226\n",
      "\n",
      "Model B (Diagnostic Model) Test Accuracy: 53.11%\n",
      "--------------------------------------------------\n",
      "\n",
      "--- STAGE 4: Live Test of the Full Pipeline ---\n",
      "Input Raw ECG Signal (first 10 values): [0.99923694 1.         0.79015642 0.56085461 0.38611218 0.23540634\n",
      " 0.12552461 0.07325448 0.07935902 0.0881343 ]...\n",
      "\n",
      "[Model A Analysis]: The most likely beat type is 'Normal (N)'\n",
      "[Model B Analysis]: Probability of being Abnormal is 0.4424\n",
      "\n",
      ">>> Final Diagnosis: Normal\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight # Import for handling imbalance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- STAGE 1: (No changes here, it's already working well) ---\n",
    "print(\"--- STAGE 1: Building and Training Beat Classifier (Model A) on MIT-BIH Data ---\")\n",
    "# ... (The entire Stage 1 code is exactly the same as the previous optimized version) ...\n",
    "try:\n",
    "    mit_train_df = pd.read_csv(\"mitbih_train.csv\", header=None)\n",
    "    mit_test_df = pd.read_csv(\"mitbih_test.csv\", header=None)\n",
    "    mit_df = pd.concat([mit_train_df, mit_test_df], axis=0)\n",
    "    print(\"MIT-BIH dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Make sure 'mitbih_train.csv' and 'mitbih_test.csv' are in the same folder.\")\n",
    "    exit()\n",
    "X_mit = mit_df.iloc[:, :-1].values\n",
    "y_mit = mit_df.iloc[:, -1].values\n",
    "y_mit_cat = to_categorical(y_mit)\n",
    "X_train_mit, X_test_mit, y_train_mit, y_test_mit = train_test_split(X_mit, y_mit_cat, test_size=0.2, random_state=42)\n",
    "model_A = Sequential([ Dense(64, activation='relu', input_shape=(187,)), Dense(32, activation='relu'), Dense(5, activation='softmax') ])\n",
    "model_A.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Training Model A...\")\n",
    "model_A.fit(X_train_mit, y_train_mit, epochs=10, batch_size=128, verbose=1, validation_split=0.1)\n",
    "loss_A, acc_A = model_A.evaluate(X_test_mit, y_test_mit, verbose=0)\n",
    "print(f\"\\nModel A (Beat Classifier) Test Accuracy: {acc_A * 100:.2f}%\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- STAGE 3: BUILD AND TRAIN THE DIAGNOSTIC MODEL (MODEL B) ---\n",
    "print(\"--- STAGE 3: Building and Training Diagnostic Model (B) on PTBDB Data ---\")\n",
    "\n",
    "# Step 3.1: Load PTBDB Data\n",
    "try:\n",
    "    ptb_normal_df = pd.read_csv(\"ptbdb_normal.csv\", header=None)\n",
    "    ptb_abnormal_df = pd.read_csv(\"ptbdb_abnormal.csv\", header=None)\n",
    "    print(\"PTBDB dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Make sure 'ptbdb_normal.csv' and 'ptbdb_abnormal.csv' are in the same folder.\")\n",
    "    exit()\n",
    "\n",
    "ptb_df = pd.concat([ptb_normal_df, ptb_abnormal_df])\n",
    "ptb_df = shuffle(ptb_df, random_state=42)\n",
    "X_ptb_raw = ptb_df.iloc[:, :-1].values\n",
    "y_ptb = ptb_df.iloc[:, -1].values\n",
    "\n",
    "# Step 3.2: Optimized Feature Engineering\n",
    "print(\"Applying optimized feature engineering pipeline to PTBDB data...\")\n",
    "prediction_probs = model_A.predict(X_ptb_raw)\n",
    "predicted_classes = np.argmax(prediction_probs, axis=1)\n",
    "X_ptb_featured = np.concatenate([prediction_probs, predicted_classes.reshape(-1, 1)], axis=1)\n",
    "print(\"Feature engineering complete.\")\n",
    "\n",
    "# Step 3.3: Prepare Data for Model B\n",
    "X_train_ptb, X_test_ptb, y_train_ptb, y_test_ptb = train_test_split(X_ptb_featured, y_ptb, test_size=0.2, random_state=42)\n",
    "\n",
    "# **IMPROVEMENT: CALCULATE CLASS WEIGHTS TO HANDLE IMBALANCE**\n",
    "# This will calculate how much to penalize errors for each class\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_ptb), # The unique classes are 0 (Normal) and 1 (Abnormal)\n",
    "    y=y_train_ptb\n",
    ")\n",
    "# The result needs to be a dictionary for Keras\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(\"\\nClass Imbalance Detected. Calculated weights to compensate:\")\n",
    "print(f\"  Weight for class 0 (Normal): {class_weights_dict[0]:.2f}\")\n",
    "print(f\"  Weight for class 1 (Abnormal): {class_weights_dict[1]:.2f}\")\n",
    "# **END OF IMPROVEMENT**\n",
    "\n",
    "# Step 3.4: Build and Train Model B\n",
    "model_B = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train_ptb.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_B.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"\\nTraining Model B (with class weights)...\")\n",
    "# **IMPROVEMENT: PASS THE WEIGHTS TO THE .fit() METHOD**\n",
    "history_B = model_B.fit(\n",
    "    X_train_ptb, y_train_ptb,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    validation_split=0.1,\n",
    "    class_weight=class_weights_dict # Here's the magic!\n",
    ")\n",
    "\n",
    "# Step 3.5: Evaluate Model B\n",
    "loss_B, acc_B = model_B.evaluate(X_test_ptb, y_test_ptb, verbose=0)\n",
    "print(f\"\\nModel B (Diagnostic Model) Test Accuracy: {acc_B * 100:.2f}%\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "# --- STAGE 4: (No changes here) ---\n",
    "print(\"--- STAGE 4: Live Test of the Full Pipeline ---\")\n",
    "def run_live_pipeline(raw_signal, model_a, model_b):\n",
    "    signal_reshaped = np.reshape(raw_signal, (1, 187))\n",
    "    live_probs = model_a.predict(signal_reshaped, verbose=0)[0]\n",
    "    live_class = np.argmax(live_probs)\n",
    "    live_features = np.append(live_probs, live_class)\n",
    "    live_features_reshaped = np.reshape(live_features, (1, -1))\n",
    "    diagnostic_prob = model_b.predict(live_features_reshaped, verbose=0)[0][0]\n",
    "    return live_class, diagnostic_prob\n",
    "\n",
    "raw_ptb_test_signals = train_test_split(X_ptb_raw, y_ptb, test_size=0.2, random_state=42)[1]\n",
    "sample_raw_signal = raw_ptb_test_signals[15]\n",
    "print(f\"Input Raw ECG Signal (first 10 values): {sample_raw_signal[:10]}...\")\n",
    "predicted_beat_idx, diagnostic_probability = run_live_pipeline(sample_raw_signal, model_A, model_B)\n",
    "beat_type_names = ['Normal (N)', 'Supraventricular (S)', 'Ventricular (V)', 'Fusion (F)', 'Unknown (Q)']\n",
    "diagnosis = \"Abnormal (Myocardial Infarction Detected)\" if diagnostic_probability > 0.5 else \"Normal\"\n",
    "print(f\"\\n[Model A Analysis]: The most likely beat type is '{beat_type_names[predicted_beat_idx]}'\")\n",
    "print(f\"[Model B Analysis]: Probability of being Abnormal is {diagnostic_probability:.4f}\")\n",
    "print(f\"\\n>>> Final Diagnosis: {diagnosis}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a513e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
